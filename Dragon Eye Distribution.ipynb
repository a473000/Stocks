{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1fc6567-6de1-43a6-a64f-d0d6403606bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "import ast\n",
    "\n",
    "import datetime\n",
    "\n",
    "from datetime import timedelta, date\n",
    "\n",
    "today = datetime.date.today()\n",
    "\n",
    "this_month=today.month\n",
    "next_month=this_month+1\n",
    "this_year=today.year\n",
    "today + datetime.timedelta(days=-today.weekday(), weeks=1)\n",
    "last_monday=today - datetime.timedelta(days=today.weekday())\n",
    "\n",
    "last_monday=today - datetime.timedelta(days=today.weekday())\n",
    "currnet_week_start=f'{last_monday}'\n",
    "\n",
    "current_year_start=f'{this_year}-01-01' \n",
    "current_year_end=f'{today}'\n",
    "\n",
    "current_month_date=f'{this_year}-{this_month}-01'\n",
    "next_month_date=f'{this_year}-{next_month}-01'  # write condition if next month is 12 reset to 01\n",
    "\n",
    "time_series_q_start=f'{this_year}-01-01' # this must be fiiled at 01,04,07,10 month of the year\n",
    "time_series_q_end=\"2023-02-01\"           #  this must be fiiled at 01,04,07,10 month of the year\n",
    "current_year_start=f'{this_year}-01-01' \n",
    "current_year_end=f'{today}'\n",
    "\n",
    "\n",
    "import os\n",
    "gwd=os.getcwd()\n",
    "path_dist='/Users/przemyslawczekaj/Downloads/My Templates Coursera/Dragon_eye/Distribution.csv'\n",
    "\n",
    "\n",
    "# these are set values that are used with chance function\n",
    "daily_desc=['-13% to -12%','-12% to -11%','-11% to -10%','-10% to -9%','-9% to -8%','-8% to -7%','-7% to -6%','-6% to -5%','-5% to -4%','-4% to -3%','-3% to -2%','-2% to -1%','-1% to 0%','0% to 1%','1% to 2%','2% to 3%','3% to 4%','4% to 5%','5% to 6%','6% to 7%','7% to 8%','8% to 9%','9% to 10%','10% to 11%','11% to 12%']\n",
    "weekly_desc=['-16% to -14%','-14% to -12%','-12% to -10%','-10% to -8%','-8% to -6%','-6% to -4%','-4% to -2%','-2% to -0%','0% to 2%','2% to 4%','4% to 6%','6% to 8%','8% to 10%','10% to 12%','12% to 14%','14% to 16%']\n",
    "monthly_desc=['-32.5% to -30%','-30% to -27.5%','-27.5% to -25%','-25% to -22.5%','-22.5% to -20%','-20% to -17.5%','-17.5% to -15%','-15% to -12.5%','-12.5% to -10%','-10% to -7.5%','-7.5% to -5%','-5% to -2.5%','-2.5% to 0%','0% to 2.5%','2.5% to 5%','5% to 7.5%','7.5% to 10%','10% to 12.5%','12.5% to 15%','15% to 17.5%','17.5% to 20%','20% to 22.5%','22.5% to 25%','25% to 27.5%','27.5% to 30%']\n",
    "quarterly_desc=['-40% to -35%','-35% to -30%','-30% to -25%','-25% to -20%','-20% to -15%','-15% to -10%','-10% to -5%','-5% to 0%','0% to 5%','5% to 10%','10% to 15%','15% to 20%','20% to 25%','25% to 30%','30% to 35%','35% to 40%']\n",
    "\n",
    "\n",
    "# this is a def to calculate cumulatie pct and giving one value on the to as df first row where chances are more then 3:1 it can be changed with value parameter\n",
    "\n",
    "def chances_std(prob,pct_description,value):\n",
    "    prob.drop(['Bin Values1','Frequency','Probabilities %'], axis=1, inplace=True)\n",
    "    prob.insert(0,\"Bin Values\", pct_description, True)\n",
    "    sorted_cum=prob.loc[prob['Probability'] <= value]\n",
    "    df_prob_part=pd.DataFrame(sorted_cum.sort_values(by=['Probability'],ascending= False))\n",
    "    df_prob_part.reset_index(drop=True, inplace=True)\n",
    "    df_prob=df_prob_part.iloc[0:1]\n",
    "    return df_prob\n",
    "\n",
    "\n",
    "\n",
    "# this function returns Standart div ,min and max in %  From \n",
    "def describe_std(df):\n",
    "    df_mean=pd.DataFrame(df.describe())\n",
    "    df_mean_t=df_mean.T\n",
    "    df_mean_t.rename(columns={\"std\": \"Std\", \"min\": \"Min\",\"max\":\"Max\"}, inplace=True)\n",
    "    df_mean_t.rename(index={'Returns': 0}, inplace=True)\n",
    "    desc=(df_mean_t[['Std','Min','Max']]*100).round(2)#.style.format('{0:,.2%}'))\n",
    "    return desc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def avgreturn_std(df):\n",
    "    pos_sorted_values=[]\n",
    "    neg_sorted_values=[]\n",
    "    count_times=len(df)\n",
    "    row=0\n",
    "    if row < count_times:\n",
    "        for value in df:\n",
    "            if value > 0:\n",
    "                    pos_sorted_values.append(value)\n",
    "            elif value < 0:\n",
    "                    neg_sorted_values.append(value)\n",
    "                    row = row + 1\n",
    "                    # we have added .loc do neg and pos\n",
    "    neg_returns=pd.DataFrame(neg_sorted_values) \n",
    "    \n",
    "    neg_sorted_returns=neg_returns[0]                            # changed here\n",
    "    \n",
    "    neg_mean= neg_sorted_returns.mean()\n",
    "    \n",
    "    #neg_mean_pct=\"{:,.2%}\".format(neg_mean)\n",
    "    pos_returns=pd.DataFrame(pos_sorted_values)\n",
    "    \n",
    "    pos_sorted_returns=pos_returns[0]                             # changed here\n",
    "    \n",
    "    pos_mean=pos_sorted_returns.mean()\n",
    "    \n",
    "    #pos_mean_pct=\"{:,.2%}\".format(pos_mean)\n",
    "    return pos_mean,neg_mean\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def retuns_std(table):\n",
    "    table[\"Returns\"]=(table['Close']- table['Open'])/table['Open']    # My First ever def  and its working\n",
    "\n",
    "    \n",
    "    # this is a def of histogram for distrbution of returns\n",
    "def dist_chart_std(df,b):\n",
    "    count,b_e = np.histogram(df, b)\n",
    "    df.plot(kind='hist',\n",
    "            figsize=(18,6),\n",
    "            bins=b,\n",
    "            edgecolor='white',\n",
    "            alpha=0.6,\n",
    "            xticks= b_e,\n",
    "            color=['darkblue'])\n",
    "    current_values = plt.gca().get_xticks()\n",
    "    plt.gca().set_xticklabels(['{:,.0%}'.format(x) for x in current_values])\n",
    "    plt.grid(color='grey', linestyle='-', linewidth=0.25)\n",
    "    \n",
    "    \n",
    "    \n",
    "# this is the working one full working with % that we want !!!!!!!!!!!!!!!!!\n",
    "\n",
    "# this function returns diffrence from open of period to open from yesterday in pct\n",
    "\n",
    "\n",
    "def diff_std(df,df_daily_open):       \n",
    "    last_period_close=(df[0])\n",
    "    current_price=(df_daily_open[0])\n",
    "    df_pct_diff=((current_price-last_period_close)/last_period_close)\n",
    "    df=pd.DataFrame([df_pct_diff])\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# This is a function to return df with Cumulative Probabilities %\n",
    "\n",
    "def cumprob_std(df,bins):\n",
    "    categories = pd.cut(df['Returns'], bins)\n",
    "    value_count=pd.DataFrame(pd.value_counts(categories))\n",
    "    value_count.reset_index(inplace=True)\n",
    "    value_count.rename(columns={'index':'Bin Values1', 'Returns':'Frequency'}, inplace= True)\n",
    "    value_count.sort_values(by='Bin Values1', ascending=True, inplace=True)\n",
    "    value_count['Probabilities %']=(value_count['Frequency']/len(df['Returns'])).round(5)\n",
    "    value_count['Probability']=(100*(value_count['Frequency'].cumsum() / value_count['Frequency'].sum())).round(2)\n",
    "    return value_count\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def std_stock(stock):\n",
    "    hist_daily=yf.download(stock, start=\"1990-01-01\", end=f'{today}', interval='1d')  # change each Month\n",
    "    hist_weekly=yf.download(stock, start=\"1990-01-01\", end=f'{today}', interval='1wk')  # change each Month\n",
    "    hist_monthly=yf.download(stock, start=\"1990-01-01\", end=f'{today}', interval='1mo') # change each Month\n",
    "    hist_quarterly=yf.download(stock, start=\"1990-01-01\", end=f'{today}', interval='3mo')  # change each Month\n",
    "\n",
    "    current_w=yf.download(stock, start=currnet_week_start, end=f'{today}', interval='1wk')  # change each Month\n",
    "    current_m=yf.download(stock, start=current_month_date, end=next_month_date, interval='1mo')  # change each Month only problem on the weeknd starting new month after that we will sort this\n",
    "    current_q=yf.download(stock, start=time_series_q_start, end=time_series_q_end, interval='3mo')  # change each Month\n",
    "    current_ytd=yf.download(stock, start=current_year_start, end=f'{today}', interval='1mo')  #End of the year close\n",
    "\n",
    "    df_hist_daily=hist_daily.sort_values(by=\"Date\", ascending=False)\n",
    "    df_hist_daily['H-Low']= df_hist_daily[\"High\"] - df_hist_daily[\"Low\"]\n",
    "    df_hist_daily[\"Daily Atr\"]= ((df_hist_daily['H-Low'].rolling(2).sum())/2)/df_hist_daily['Open']\n",
    "    df_hist_daily.style.format(\"{:.2%}\")\n",
    "    retuns_std(df_hist_daily)\n",
    "\n",
    "    df_hist_weekly=hist_weekly.sort_values(by=\"Date\", ascending=False)\n",
    "    df_hist_weekly['H-Low']= df_hist_weekly[\"High\"] - df_hist_weekly[\"Low\"]\n",
    "    df_hist_weekly[\"Weekly Atr\"]= ((df_hist_weekly['H-Low'].rolling(2).sum())/2)/df_hist_weekly['Open']\n",
    "    retuns_std(df_hist_weekly)\n",
    "\n",
    "    df_hist_monthly=hist_monthly.sort_values(by=\"Date\", ascending=False)\n",
    "    df_hist_monthly['H-Low']= df_hist_monthly[\"High\"] - df_hist_monthly[\"Low\"]\n",
    "    df_hist_monthly[\"Monthly Atr\"]= ((df_hist_monthly['H-Low'].rolling(2).sum())/2)/df_hist_monthly['Open']\n",
    "    retuns_std(df_hist_monthly)\n",
    "\n",
    "\n",
    "    df_hist_quarterly=hist_quarterly.sort_values(by=\"Date\", ascending=False)\n",
    "    df_hist_quarterly['H-Low']= df_hist_quarterly[\"High\"] - df_hist_quarterly[\"Low\"]\n",
    "    df_hist_quarterly[\"Quarterly Atr\"]= ((df_hist_quarterly['H-Low'].rolling(2).sum())/2)/df_hist_quarterly['Open']\n",
    "    retuns_std(df_hist_quarterly)\n",
    "\n",
    "\n",
    "\n",
    "    atr_quarterly_3=df_hist_quarterly[\"Quarterly Atr\"].iloc[1:4]\n",
    "    atr_mean_q_3=atr_quarterly_3.mean()\n",
    "    Q_ATR_3=\"{:.0%}\".format(atr_mean_q_3)\n",
    "\n",
    "\n",
    "    atr_quarterly_6=df_hist_quarterly[\"Quarterly Atr\"].iloc[1:7]\n",
    "    atr_mean_q_6=atr_quarterly_6.mean()\n",
    "    Q_ATR_6=\"{:.0%}\".format(atr_mean_q_6)\n",
    "\n",
    "    atr_quarterly_9=df_hist_quarterly[\"Quarterly Atr\"].iloc[1:10]\n",
    "    atr_mean_q_9=atr_quarterly_9.mean()\n",
    "    Q_ATR_9=\"{:.0%}\".format(atr_mean_q_9)\n",
    "\n",
    "\n",
    "    atr_quarterly_12=df_hist_quarterly[\"Quarterly Atr\"].iloc[1:13]\n",
    "    atr_mean_q_12=atr_quarterly_12.mean()\n",
    "    Q_ATR_12=\"{:.0%}\".format(atr_mean_q_12)\n",
    "\n",
    "\n",
    "    atr_quarterly_24=df_hist_quarterly[\"Quarterly Atr\"].iloc[1:25]\n",
    "    atr_mean_q_24=atr_quarterly_24.mean()\n",
    "    Q_ATR_24=\"{:.0%}\".format(atr_mean_q_24)\n",
    "\n",
    "\n",
    "    atr_quarterly_max=df_hist_quarterly[\"Quarterly Atr\"]\n",
    "    atr_mean_q_max=atr_quarterly_max.mean()\n",
    "    Q_ATR_MAX=\"{:.0%}\".format(atr_mean_q_max)\n",
    "\n",
    "\n",
    "    atr_df_Q={'Q ATR 3':[Q_ATR_3],'Q ATR 6':[Q_ATR_6],'Q ATR 9':[Q_ATR_9],'Q ATR 12':[Q_ATR_12],'Q ATR 24':[Q_ATR_24],'Q ATR Max':[Q_ATR_MAX]}\n",
    "    atr_q=pd.DataFrame(atr_df_Q)\n",
    "\n",
    "\n",
    "        #df_q_atr=df_atr_q.rename(index={0: \"Quarterly\"})\n",
    "\n",
    "\n",
    "\n",
    "    atr_monthly_3=df_hist_monthly[\"Monthly Atr\"].iloc[1:4]\n",
    "    atr_mean_m_3=atr_monthly_3.mean()\n",
    "    atr_monthly_3_pc=\"{:.0%}\".format(atr_mean_m_3)\n",
    "\n",
    "    atr_monthly_6=df_hist_monthly[\"Monthly Atr\"].iloc[1:7]\n",
    "    atr_mean_m_6=atr_monthly_6.mean()\n",
    "    atr_monthly_6_pc=\"{:.0%}\".format(atr_mean_m_6)\n",
    "\n",
    "    atr_monthly_9=df_hist_monthly[\"Monthly Atr\"].iloc[1:10]\n",
    "    atr_mean_m_9=atr_monthly_9.mean()\n",
    "    atr_monthly_9_pc=\"{:.0%}\".format(atr_mean_m_9)\n",
    "\n",
    "    atr_monthly_12=df_hist_monthly[\"Monthly Atr\"].iloc[1:13]\n",
    "    atr_mean_m_12=atr_monthly_12.mean()\n",
    "    atr_monthly_12_pc=\"{:.0%}\".format(atr_mean_m_12)\n",
    "\n",
    "    atr_monthly_24=df_hist_monthly[\"Monthly Atr\"].iloc[1:25]\n",
    "    atr_mean_m_24=atr_monthly_24.mean()\n",
    "    atr_monthly_24_pc=\"{:.0%}\".format(atr_mean_m_24)\n",
    "\n",
    "\n",
    "    atr_monthly_max=df_hist_monthly[\"Monthly Atr\"]\n",
    "    atr_mean_m_max=atr_monthly_max.mean()\n",
    "    atr_monthly_max_pc=\"{:.0%}\".format(atr_mean_m_max)\n",
    "\n",
    "    atr_df_m={'M ATR 3':[atr_monthly_3_pc],'M ATR 6':[atr_monthly_6_pc],'M ATR 9':[atr_monthly_9_pc],'M ATR 12':[atr_monthly_12_pc],'M ATR 24':[atr_monthly_24_pc],'M ATR Max':[atr_monthly_max_pc]}\n",
    "    atr_m=pd.DataFrame(atr_df_m)\n",
    "\n",
    "\n",
    "    atr_weekly_12=df_hist_weekly[\"Weekly Atr\"].iloc[1:12]\n",
    "    atr_mean_w_12=atr_weekly_12.mean()\n",
    "    atr_weekly_12_pc=\"{:.0%}\".format(atr_mean_w_12)\n",
    "\n",
    "    atr_weekly_26=df_hist_weekly[\"Weekly Atr\"].iloc[1:27]\n",
    "    atr_mean_w_26=atr_weekly_26.mean()\n",
    "    atr_weekly_26_pc=\"{:.0%}\".format(atr_mean_w_26)\n",
    "\n",
    "    atr_weekly_52=df_hist_weekly[\"Weekly Atr\"].iloc[1:53]\n",
    "    atr_mean_w_52=atr_weekly_52.mean()\n",
    "    atr_weekly_52_pc=\"{:.0%}\".format(atr_mean_w_52)\n",
    "\n",
    "\n",
    "    atr_weekly_104=df_hist_weekly[\"Weekly Atr\"].iloc[1:105]\n",
    "    atr_mean_w_104=atr_weekly_104.mean()\n",
    "    atr_weekly_104_pc=\"{:.0%}\".format(atr_mean_w_104)\n",
    "\n",
    "\n",
    "\n",
    "    atr_weekly_156=df_hist_weekly[\"Weekly Atr\"].iloc[1:157]\n",
    "    atr_mean_w_156=atr_weekly_156.mean()\n",
    "    atr_weekly_156_pc=\"{:.0%}\".format(atr_mean_w_156)\n",
    "\n",
    "    atr_weekly_max=df_hist_weekly[\"Weekly Atr\"]\n",
    "    atr_mean_w_max=atr_weekly_max.mean()\n",
    "    atr_weekly_max_pc=\"{:.0%}\".format(atr_mean_w_max)\n",
    "\n",
    "\n",
    "    atr_df_w={'W ATR 12':[atr_weekly_12_pc],'W ATR 26':[atr_weekly_26_pc],'W ATR 52':[atr_weekly_52_pc],'W ATR 2 Years':[atr_weekly_104_pc],'W ATR 3 Years':[atr_weekly_156_pc],'W ATR Max':[atr_weekly_max_pc]}\n",
    "    atr_w=pd.DataFrame(atr_df_w)\n",
    "\n",
    "\n",
    "\n",
    "    atr_daily_6=df_hist_daily[\"Daily Atr\"].iloc[1:7]\n",
    "    atr_mean_d_6=atr_daily_6.mean()\n",
    "    atr_daily_6_pc=\"{:.0%}\".format(atr_mean_d_6)\n",
    "\n",
    "    atr_daily_24=df_hist_daily[\"Daily Atr\"].iloc[1:25]\n",
    "    atr_mean_d_24=atr_daily_24.mean()\n",
    "    atr_daily_24_pc=\"{:.0%}\".format(atr_mean_d_24)\n",
    "    atr_daily_72=df_hist_daily[\"Daily Atr\"].iloc[1:73]\n",
    "    atr_mean_d_72=atr_daily_72.mean()\n",
    "    atr_daily_72_pc=\"{:.0%}\".format(atr_mean_d_72)\n",
    "\n",
    "    atr_daily_288=df_hist_daily[\"Daily Atr\"].iloc[1:289]\n",
    "    atr_mean_d_288=atr_daily_288.mean()\n",
    "    atr_daily_288_pc=\"{:.0%}\".format(atr_mean_d_288)\n",
    "\n",
    "    atr_daily_576=df_hist_daily[\"Daily Atr\"].iloc[1:577]\n",
    "    atr_mean_d_576=atr_daily_576.mean()\n",
    "    atr_daily_576_pc=\"{:.0%}\".format(atr_mean_d_576)\n",
    "\n",
    "    atr_daily_576=df_hist_daily[\"Daily Atr\"].iloc[1:577]\n",
    "    atr_mean_d_576=atr_daily_576.mean()\n",
    "    atr_daily_576_pc=\"{:.0%}\".format(atr_mean_d_576)\n",
    "\n",
    "    atr_daily_max=df_hist_daily[\"Daily Atr\"]\n",
    "    atr_mean_d_max=atr_daily_max.mean()\n",
    "    atr_daily_max_pc=\"{:.0%}\".format(atr_mean_d_max)\n",
    "\n",
    "    atr_df_d={'D ATR 6':[atr_daily_6_pc],'D ATR 24':[atr_daily_24_pc],'D ATR 72':[atr_daily_72_pc],'D ATR 288':[atr_daily_288_pc],'D ATR 576':[atr_daily_576_pc],'D ATR Max':[atr_daily_max_pc]}\n",
    "    atr_d=pd.DataFrame(atr_df_d)\n",
    "\n",
    "        # bins for distribution \n",
    "    bins_d=(np.arange(-0.13,0.13,0.01).round(3))\n",
    "    bins_w=(np.arange(-0.16,0.18, 0.02).round(3))\n",
    "    bins_m=(np.arange(-0.325,0.325, 0.025).round(3))\n",
    "    bins_q=(np.arange(-0.4,0.45, 0.05).round(3))\n",
    "        # bin ticks for chart\n",
    "    count,bins_ticks_d = np.histogram(df_hist_daily['Returns'], bins_d)\n",
    "    count,bins_ticks_w = np.histogram(df_hist_weekly['Returns'], bins_w)\n",
    "    count,bins_ticks_m = np.histogram(df_hist_monthly['Returns'], bins_m)\n",
    "    count,bins_ticks_q = np.histogram(df_hist_quarterly['Returns'], bins_q)\n",
    "        # at this stage all charts are working\n",
    "\n",
    "        # all avg pos nad neg calculation pct and into one df\n",
    "    returns_daily = avgreturn_std(df_hist_daily['Returns'])\n",
    "    returns_daily_pos=returns_daily[0]\n",
    "    returns_daily_neg=returns_daily[1]\n",
    "    returns_daily_pos=\"{:.2%}\".format(returns_daily_pos)\n",
    "    returns_daily_neg=\"{:.2%}\".format(returns_daily_neg)\n",
    "    returns_daily={'Daily Pos':[returns_daily_pos],'Daily Neg':[returns_daily_neg]}\n",
    "    returns_daily=pd.DataFrame(returns_daily)\n",
    "\n",
    "    returns_weekly = avgreturn_std(df_hist_weekly['Returns'])\n",
    "    returns_weekly_pos=returns_weekly[0]\n",
    "    returns_weekly_neg=returns_weekly[1]\n",
    "    returns_weekly_pos=\"{:.2%}\".format(returns_weekly_pos)\n",
    "    returns_weekly_neg=\"{:.2%}\".format(returns_weekly_neg)\n",
    "    returns_weekly={'Weekly Pos':[returns_weekly_pos],'Weekly Neg':[returns_weekly_neg]}\n",
    "    returns_weekly=pd.DataFrame(returns_weekly)\n",
    "\n",
    "    returns_monthly = avgreturn_std(df_hist_monthly['Returns'])\n",
    "    returns_monthly_pos=returns_monthly[0]\n",
    "    returns_monthly_neg=returns_monthly[1]\n",
    "    returns_monthly_pos=\"{:.2%}\".format(returns_monthly_pos)\n",
    "    returns_monthly_neg=\"{:.2%}\".format(returns_monthly_neg)\n",
    "    returns_monthly={'Monthly Pos':[returns_monthly_pos],'Monthly Neg':[returns_monthly_neg]}\n",
    "    returns_monthly=pd.DataFrame(returns_monthly)\n",
    "\n",
    "\n",
    "    returns_quaterly = avgreturn_std(df_hist_quarterly['Returns'])\n",
    "    returns_quaterly_pos=returns_quaterly[0]\n",
    "    returns_quaterly_neg=returns_quaterly[1]\n",
    "    returns_quaterly_pos=\"{:.2%}\".format(returns_quaterly_pos)\n",
    "    returns_quaterly_neg=\"{:.2%}\".format(returns_quaterly_neg)\n",
    "    returns_quaterly={'Quaterly Pos':[returns_quaterly_pos],'Quaterly Neg':[returns_quaterly_neg]}\n",
    "    returns_quaterly=pd.DataFrame(returns_quaterly)\n",
    "\n",
    "\n",
    "\n",
    "        # current price diffrence or period like week month quarter and its correct more test as we go along  this is wrong PLEASE FIX THIS\n",
    "\n",
    "\n",
    "    if last_monday==today:\n",
    "        weekly_empty=['Null']\n",
    "        date=f'{today}'\n",
    "        current_price_w=pd.DataFrame(weekly_empty)\n",
    "        current_price_w.rename(columns={0:'Weekly'}, inplace=True)\n",
    "        \n",
    "    else:\n",
    "        current_price_w=diff_std(current_w['Open'], df_hist_daily['Close'])\n",
    "        current_price_w=diff_std(current_w['Open'], df_hist_daily['Close'])\n",
    "        current_price_w.rename(columns={0:\"Week\"},inplace=True)\n",
    "        current_price_w=current_price_w.loc[0][0]\n",
    "        current_price_w=\"{:.2%}\".format(current_price_w)\n",
    "        current_price_w={'Weekly':[current_price_w]}\n",
    "        current_price_w=pd.DataFrame(current_price_w)\n",
    "\n",
    "    current_price_m=diff_std(current_m['Open'], df_hist_daily['Close'])\n",
    "    current_price_m.rename(columns={0:\"Month\"},inplace=True)\n",
    "    current_price_m=current_price_m.loc[0][0]\n",
    "    current_price_m=\"{:.2%}\".format(current_price_m)\n",
    "    current_price_m={'Monthly':[current_price_m]}\n",
    "    current_price_m=pd.DataFrame(current_price_m)\n",
    "\n",
    "    current_price_q=diff_std(current_q['Open'], df_hist_daily['Close'])\n",
    "    current_price_q.rename(columns={0:\"Quarter\"},inplace=True)\n",
    "    current_price_q=current_price_q.loc[0][0]\n",
    "    current_price_q=\"{:.2%}\".format(current_price_q)\n",
    "    current_price_q={'Quarterly':[current_price_q]}\n",
    "    current_price_q=pd.DataFrame(current_price_q)\n",
    "\n",
    "    current_price_ytd=diff_std(current_ytd['Open'], df_hist_daily['Close'])\n",
    "    current_price_ytd.rename(columns={0:\"Year to Date\"},inplace=True)\n",
    "    current_price_ytd=current_price_ytd.loc[0][0]\n",
    "    current_price_ytd=\"{:.2%}\".format(current_price_ytd)\n",
    "    current_price_ytd={'YTD':[current_price_ytd]}\n",
    "    current_price_ytd=pd.DataFrame(current_price_ytd)\n",
    "\n",
    "        # using describe function we get describe for all periods \n",
    "\n",
    "\n",
    "    #describe_d=describe(df_hist_daily['Returns'])\n",
    "    #describe_w=describe(df_hist_weekly['Returns'])\n",
    "    #describe_m=describe(df_hist_monthly['Returns'])\n",
    "    #describe_q=describe(df_hist_quarterly['Returns'])\n",
    "\n",
    "        # The following lines are for d,w,m,q cumulative probabilities df from the function cumprob\n",
    "    cum_prob_d=cumprob_std(df_hist_daily,bins_d)\n",
    "    cum_prob_w=cumprob_std(df_hist_weekly,bins_w)\n",
    "    cum_prob_m=cumprob_std(df_hist_monthly,bins_m)\n",
    "    cum_prob_q=cumprob_std(df_hist_quarterly,bins_q)\n",
    "\n",
    "    chances_prob_d=chances_std(cum_prob_d,daily_desc,30)\n",
    "    chances_prob_d.rename(columns={\"Bin Values\":\"D Between\", \"Probability\":\"D Chance\"}, inplace=True)\n",
    "    chances_prob_w=chances_std(cum_prob_w,weekly_desc,30)\n",
    "    chances_prob_w.rename(columns={\"Bin Values\":\"W Between\", \"Probability\":\"W Chance\"}, inplace=True)\n",
    "    chances_prob_w_pct_between=chances_prob_w.iloc[0][0]\n",
    "    chances_prob_w_pct_chance=chances_prob_w.iloc[0][1]\n",
    "    chances_prob_w_pct_chance=(chances_prob_w_pct_chance)/100\n",
    "    chances_prob_w_pct_chance=\"{:.2%}\".format(chances_prob_w_pct_chance)\n",
    "    chances_prob_w_pct={'Range':[chances_prob_w_pct_between],'Probability':[chances_prob_w_pct_chance]}\n",
    "    chances_prob_w=pd.DataFrame(chances_prob_w_pct)\n",
    "\n",
    "    chances_prob_m=chances_std(cum_prob_m,monthly_desc,30)\n",
    "    chances_prob_m.rename(columns={\"Bin Values\":\"M Between\", \"Probability\":\"M Chance\"}, inplace=True)\n",
    "    chances_prob_m_pct_between=chances_prob_m.iloc[0][0]\n",
    "    chances_prob_m_pct_chance=chances_prob_m.iloc[0][1]\n",
    "    chances_prob_m_pct_chance=(chances_prob_m_pct_chance)/100\n",
    "    chances_prob_m_pct_chance=\"{:.2%}\".format(chances_prob_m_pct_chance)\n",
    "    chances_prob_m_pct={'Range':[chances_prob_m_pct_between],'Probability':[chances_prob_m_pct_chance]}\n",
    "    chances_prob_m=pd.DataFrame(chances_prob_m_pct)\n",
    "\n",
    "    chances_prob_q=chances_std(cum_prob_q,quarterly_desc,30)\n",
    "    chances_prob_q.rename(columns={\"Bin Values\":\"Q Between\", \"Probability Q\":\"Q Chance\"}, inplace=True)\n",
    "    chances_prob_q_pct_between=chances_prob_q.iloc[0][0]\n",
    "    chances_prob_q_pct_chance=chances_prob_q.iloc[0][1]\n",
    "    chances_prob_q_pct_chance=(chances_prob_q_pct_chance)/100\n",
    "    chances_prob_q_pct_chance=\"{:.2%}\".format(chances_prob_q_pct_chance)\n",
    "    chances_prob_q_pct={'Range':[chances_prob_q_pct_between],'Probability Q':[chances_prob_q_pct_chance]}\n",
    "    chances_prob_q=pd.DataFrame(chances_prob_q_pct)\n",
    "    chances_prob_q.rename(columns={'Range':'Range Q'}, inplace=True)\n",
    "\n",
    "\n",
    "    #stock_stats=pd.concat([current_price_ytd,current_price_q,current_price_m,current_price_w,chances_prob_q,df_returns_q_t,atr_q['Q ATR Max'],describe_q,chances_prob_m,df_returns_m_t,atr_m['M ATR 9'],describe_m,chances_prob_w,df_returns_w_t,atr_w['W ATR 12'],describe_w],axis=1)\n",
    "    stock_stats=pd.concat([current_price_ytd['YTD'],current_price_q['Quarterly'],current_price_m['Monthly'],current_price_w['Weekly'],chances_prob_q['Range Q'],chances_prob_q['Probability Q'],\n",
    "                          returns_quaterly['Quaterly Pos'],returns_quaterly['Quaterly Neg'],atr_q['Q ATR Max'],chances_prob_m['Range'],chances_prob_m['Probability'],returns_monthly['Monthly Pos'],\n",
    "                          returns_monthly['Monthly Neg'],atr_m['M ATR 9'],returns_weekly['Weekly Pos'],returns_weekly['Weekly Neg']],axis=1)\n",
    "    stock_stats.index=[f'{stock}']\n",
    "    return stock_stats\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15d56614-1786-4b1b-9008-b6e1ffdeaaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YTD</th>\n",
       "      <th>Quarterly</th>\n",
       "      <th>Monthly</th>\n",
       "      <th>Weekly</th>\n",
       "      <th>Range Q</th>\n",
       "      <th>Probability Q</th>\n",
       "      <th>Quaterly Pos</th>\n",
       "      <th>Quaterly Neg</th>\n",
       "      <th>Q ATR Max</th>\n",
       "      <th>Range</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Monthly Pos</th>\n",
       "      <th>Monthly Neg</th>\n",
       "      <th>M ATR 9</th>\n",
       "      <th>Weekly Pos</th>\n",
       "      <th>Weekly Neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WBA</th>\n",
       "      <td>-7.27%</td>\n",
       "      <td>-7.27%</td>\n",
       "      <td>0.60%</td>\n",
       "      <td>-0.62%</td>\n",
       "      <td>-10% to -5%</td>\n",
       "      <td>26.87%</td>\n",
       "      <td>11.28%</td>\n",
       "      <td>-8.06%</td>\n",
       "      <td>21%</td>\n",
       "      <td>-7.5% to -5%</td>\n",
       "      <td>19.25%</td>\n",
       "      <td>6.31%</td>\n",
       "      <td>-5.10%</td>\n",
       "      <td>14%</td>\n",
       "      <td>2.90%</td>\n",
       "      <td>-2.75%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        YTD Quarterly Monthly  Weekly      Range Q Probability Q Quaterly Pos  \\\n",
       "WBA  -7.27%    -7.27%   0.60%  -0.62%  -10% to -5%        26.87%       11.28%   \n",
       "\n",
       "    Quaterly Neg Q ATR Max         Range Probability Monthly Pos Monthly Neg  \\\n",
       "WBA       -8.06%       21%  -7.5% to -5%      19.25%       6.31%      -5.10%   \n",
       "\n",
       "    M ATR 9 Weekly Pos Weekly Neg  \n",
       "WBA     14%      2.90%     -2.75%  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_stock(\"WBA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5798fb25-a1b2-4a67-8780-c1eceabe84a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
